{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOKV/eU9Xwxn7RYe68zJdmQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdi-nait/ENSIM_AI_Lab/blob/master/Audio_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature extraction"
      ],
      "metadata": {
        "id": "pbUoyA6x1VWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature exploration"
      ],
      "metadata": {
        "id": "_SRNwoLco6K2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Dataset\\ part\\ 1.zip\n",
        "!unzip Dataset\\ part\\ 2.zip"
      ],
      "metadata": {
        "id": "uP4SUNGL1d38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import librosa as lr\n",
        "import numpy as np\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import pywt\n",
        "import random\n",
        "import torch\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from torch.utils.data import DataLoader,TensorDataset,Dataset\n",
        "import os\n",
        "from torchvision import transforms\n",
        "!pip install wandb\n",
        "import wandb"
      ],
      "metadata": {
        "id": "vwbamjqfV0Ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"Dataset/\"\n",
        "#Reading data Info file\n",
        "\n",
        "df = pd.read_csv(train_path+\"0Info.txt\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "3P_SR4xVVoPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding column names to df to make querying easier\n",
        "df.columns = [\"filename\",\"link\",\"timestamp\",\"lang\"]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "JI4t6CFZXUAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = train_path+df[\"filename\"][0]\n",
        "sr = 16000\n",
        "\n",
        "\n",
        "x,freq = lr.load(filename,sr)\n",
        "print (\" The duration of FR_001 .wav in seconds :\",len (x)/ freq )\n",
        "plt.plot(x)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "raCMMqu0XwEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_mfcc = lr.feature.mfcc(x,sr=freq,n_mfcc=40)\n",
        "print(x_mfcc.shape)\n",
        "plt.plot(x_mfcc)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r8iY4CISYdih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_c = lr.feature.spectral_centroid(x)\n",
        "print(s_c.shape)\n",
        "plt.plot(s_c[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0wPumqBkrKbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spect_roll = lr.feature.spectral_rolloff(x,sr=sr)\n",
        "print(spect_roll.shape)\n",
        "plt.plot(spect_roll[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZkNpQd3GrgG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chroma=lr.feature.chroma_stft(y=x, sr=sr)\n",
        "print(chroma.shape)\n",
        "librosa.display.specshow(chroma, y_axis='chroma', x_axis='time')\n",
        "plt.colorbar()\n",
        "plt.title('Chromagram')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "Q74g_HgArsVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S = lr.magphase(lr.stft(x, window=np.ones, center=False))[0]\n",
        "RMSEn= lr.feature.rms(S=S)\n",
        "print(chroma.shape)\n",
        "plt.plot(RMSEn[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XOjLOt6vr1Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset preparation helping functions"
      ],
      "metadata": {
        "id": "2Jt_u9Fno-uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extractor(audio_file_dir):\n",
        "\n",
        "  SAMPLE_RATE = 16000\n",
        "  x,freq = lr.load(audio_file_dir,SAMPLE_RATE)\n",
        "\n",
        "  mfcc = lr.feature.mfcc(x,sr=freq,n_mfcc=20)\n",
        "  mean_mfccs = np.mean(mfcc,axis=1)\n",
        "  var_mfccs = np.var(mfcc,axis=1)\n",
        "  \n",
        "  return list(mean_mfccs)+list(var_mfccs)"
      ],
      "metadata": {
        "id": "ayiDnH05pSrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trim_audio(X,freq,duration):\n",
        "\n",
        "  #print(f\"target {freq*duration} samples\")\n",
        "  #print(f\"current {len(X)} samples\")\n",
        "\n",
        "  target_sample_len = freq*duration\n",
        "  current_len = len(X)\n",
        "  \n",
        "  if current_len >=target_sample_len:\n",
        "    \n",
        "    X_duration = X[:target_sample_len]\n",
        "    return X_duration\n",
        "    \n",
        "  else:\n",
        "    \n",
        "    pad_len = target_sample_len-current_len\n",
        "    X_pad =pywt.pad(X,(pad_len,0),\"zero\")\n",
        "    return X_pad \n"
      ],
      "metadata": {
        "id": "kEAMEl58qp7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "xHJdJb_Fj38Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Composing filenames from 0Info.txt dataframe\n",
        "\n",
        "filenames = list(df[\"filename\"])\n",
        "SAMPLE_RATE = 16000\n",
        "root = \"Dataset/\"\n",
        "filenames = [root + X for X in filenames]"
      ],
      "metadata": {
        "id": "PNzyMKNxUCX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset preparation\n",
        "X_train = [feature_extractor(X) for X in filenames]\n",
        "Y_train = list(df[\"lang\"])\n",
        "\n",
        "#Encoding the targets\n",
        "lang_dict = {\"EN\":0, \"FR\":1, \"AR\":2, \"JP\":3}\n",
        "Y_train = [lang_dict[X] for X in Y_train]\n",
        "\n",
        "#Shuffle\n",
        "\n",
        "zipped_list = list(zip(X_train,Y_train))\n",
        "random.shuffle(zipped_list)\n",
        "X_train,Y_train = zip(*zipped_list)"
      ],
      "metadata": {
        "id": "OryTSWDfW9AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dummy classifier (Baseline)"
      ],
      "metadata": {
        "id": "bFp3Wkmrmdnj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following classifier is used to benchmark our models, to see if they do better than a most frequent strategy dummy classifier"
      ],
      "metadata": {
        "id": "J152oYawpYRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(X_train,Y_train)\n",
        "print(\" Accuracy \", dummy_clf.score(X_train,Y_train))"
      ],
      "metadata": {
        "id": "AXABkbm5mgjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## random forest clasifier"
      ],
      "metadata": {
        "id": "8YcyPDlikTXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "clf = clf.fit(X_train,Y_train)\n",
        "print(\" Accuracy \", clf.score(X_train,Y_train))"
      ],
      "metadata": {
        "id": "T_A1JCvjkcwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = { \n",
        "    'n_estimators': [200, 500,1000],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'criterion' :['gini', 'entropy']\n",
        "}"
      ],
      "metadata": {
        "id": "wBErQIkRp7tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "CV_rfc = GridSearchCV(estimator=clf, param_grid=param_grid, cv= 5)\n",
        "CV_rfc.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "y0AGlZt-qD6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CV_rfc.best_params_"
      ],
      "metadata": {
        "id": "k5HZsUiZqRpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfc1=RandomForestClassifier(random_state=0, max_features='auto', n_estimators= 500, max_depth=3, criterion='entropy')\n",
        "rfc1 = rfc1.fit(X_train,Y_train)\n",
        "print(\" Accuracy \", rfc1.score(X_train,Y_train))"
      ],
      "metadata": {
        "id": "nUlw3zPRqdPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dense Neural network"
      ],
      "metadata": {
        "id": "TmWL6_k8nMzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(Y):\n",
        "\n",
        "  lang_dict = {\"EN\":0, \"FR\":1, \"AR\":2, \"JP\":3}\n",
        "  one_hot_mat = np.eye(len(lang_dict))\n",
        "\n",
        "  Y = [list(one_hot_mat[lang_dict[x]]) for x in Y]\n",
        "  return Y"
      ],
      "metadata": {
        "id": "nO5k1_P837nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df[\"filename\"]!=\"0Info.txt\"]\n",
        "df"
      ],
      "metadata": {
        "id": "PIAgJV148dZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Audio_Dataset(Dataset):\n",
        "\n",
        "  def __init__(self,data_dir,txt_filename,sample_rate = 16000):\n",
        "    \n",
        "    self.data_dir = data_dir\n",
        "    self.sample_rate = sample_rate\n",
        "    \n",
        "    \n",
        "    df = pd.read_csv(data_dir+txt_filename)\n",
        "    \n",
        "    df.columns = [\"filename\",\"link\",\"timestamp\",\"lang\"]\n",
        "    \n",
        "    filenames = list(df[\"filename\"])\n",
        "    labels = list(df[\"lang\"])\n",
        "    self.filenames = [data_dir+x for x in filenames]\n",
        "    self.labels = one_hot(labels)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.filenames)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "\n",
        "    \n",
        "    X,freq = lr.load(self.filenames[idx],sr = self.sample_rate)\n",
        "    \n",
        "    X = lr.feature.mfcc(x,sr=freq,n_mfcc=20)\n",
        "    Y = self.labels[idx]\n",
        "    \n",
        "    X = torch.Tensor(X)\n",
        "    Y = torch.Tensor(Y)\n",
        "\n",
        "    return X,Y"
      ],
      "metadata": {
        "id": "0EHTjyyWvIEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Audio_Dataset(data_dir,\"0Info.txt\")\n",
        "batch_size = 1\n",
        "dataset_train,dataset_validation = torch.utils.data.random_split(dataset, [299, 100 ], generator=torch.Generator().manual_seed(42))\n",
        "train_loader = DataLoader(dataset_train,batch_size=batch_size,shuffle = True)\n",
        "validation_loader = DataLoader(dataset_validation,batch_size=batch_size,shuffle = True)"
      ],
      "metadata": {
        "id": "B9P3g7S6FpNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork,self).__init__()\n",
        "\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_stack = nn.Sequential(\n",
        "        nn.Linear(20*157,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256,4)\n",
        "    )\n",
        "\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "  def forward(self,X):\n",
        "\n",
        "    X = self.flatten(X)\n",
        "    logits = self.linear_stack(X)\n",
        "    logits = self.softmax(logits)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "m-hPzaVbp4kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,train_loader,valid_loader,loss_fn,optimizer,epochs,batch_size =1):\n",
        "\n",
        "  for i in range(epochs):\n",
        "    \n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    total_test_loss = 0\n",
        "    val_correct = 0\n",
        "    train_correct = 0\n",
        "    for _, (X,Y) in enumerate(train_loader):\n",
        "\n",
        "      pred = model(X)\n",
        "      #y_pred = torch.log_softmax(pred,dim=1)\n",
        "      loss = loss_fn(pred,Y)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      total_train_loss+=loss.item()\n",
        "      train_correct += (pred.argmax(1)==1).type(torch.float).sum().item()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      \n",
        "      for _, (X,Y) in enumerate(valid_loader):\n",
        "        pred = model(X)\n",
        "        total_test_loss += loss_fn(pred, Y).item()\n",
        "        val_correct += (pred.argmax(1)==1).type(torch.float).sum().item()\n",
        "\n",
        "\n",
        "    train_steps = len(train_loader.dataset) // batch_size\n",
        "    test_steps = len(valid_loader.dataset) // batch_size\n",
        "\n",
        "    avgTrainLoss = total_train_loss / train_steps\n",
        "    avgTestLoss = total_test_loss / test_steps\n",
        "    val_accuracy = val_correct/len(validation_loader.dataset)\n",
        "    train_accuracy = train_correct/len(train_loader.dataset)\n",
        "\n",
        "    print(\"[INFO] EPOCH: {}/{}\".format(i+ 1, epochs))\n",
        "    print(\"Train loss: {:.6f}, Train accuracy {:.3f},Test loss: {:.4f}, Validation accuracy {:.4f}\".format(avgTrainLoss, train_accuracy,avgTestLoss,val_accuracy))"
      ],
      "metadata": {
        "id": "ienON4aTf114"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=1e-2,momentum = 0.99)"
      ],
      "metadata": {
        "id": "2Tp2kVmErJed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model,train_loader,validation_loader,loss_fn,optimizer,10,1)"
      ],
      "metadata": {
        "id": "Sxvs_0aFkej2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,Y = next(iter(train_loader))\n",
        "output = model(X)\n",
        "softmax = nn.Softmax(dim=1)\n",
        "#output = softmax(output)\n",
        "correct =0\n",
        "correct += (output.argmax(1)==1).type(torch.float).sum().item()\n",
        "print(output)\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "-OtIMu_RrouS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.argmax(1)==1"
      ],
      "metadata": {
        "id": "_JXGsr7e0UMG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}